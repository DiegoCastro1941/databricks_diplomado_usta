{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b92656df-cbb9-4828-9df9-ca91e82b0f2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS main.diplomado_datos.ids_contratos_procesos;\n",
    "DROP TABLE IF EXISTS main.diplomado_datos.secop_id_bronze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66093278-d4f8-4ab8-9c8e-a2a0638e09d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE DATABASE IF NOT EXISTS main.diplomado_datos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa6bb82f-9c23-4600-a7aa-9049a34b48d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW TABLES IN main.diplomado_datos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d6a55ae-d32c-402e-b5b0-3deb4a1e800b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS main.diplomado_datos.ids_contratos_procesos (\n",
    "    numero_del_contrato STRING,\n",
    "    numero_de_proceso STRING,\n",
    "    nit_de_la_entidad STRING,\n",
    "    documento_proveedor STRING,\n",
    "    estado_del_proceso STRING\n",
    ")\n",
    "USING DELTA;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8ab1c72-62a3-459e-9487-15676cc24cad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW TABLES IN main.diplomado_datos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24dd25ed-8a43-4ad8-a11f-61273f25381f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "\n",
    "#client = Socrata(\"www.datos.gov.co\", None)\n",
    "\n",
    "token = dbutils.secrets.get(\"claves\",\"token_app\")\n",
    "codigo_dataset = dbutils.widgets.get(\"codigo_dataset\")\n",
    "# Example authenticated client (needed for non-public datasets):\n",
    "client = Socrata(\"www.datos.gov.co\", str(token), timeout=50)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2eac35c-e3a6-4559-8f0d-f751d37b5389",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# 3. Parámetros de paginación\n",
    "limit = 500000\n",
    "offset = 0\n",
    "write_mode = \"overwrite\"\n",
    "reintentos=5\n",
    "\n",
    "print(f\"Iniciando carga por lotes para el dataset: {codigo_dataset}\")\n",
    "\n",
    "# 4. Bucle para obtener y cargar los datos por lotes\n",
    "while True:\n",
    "    intentos = 0\n",
    "\n",
    "    while intentos < reintentos:\n",
    "        try:\n",
    "            print(f\"Obteniendo y cargando lote {offset}...\")\n",
    "            # Construye y ejecuta la consulta para el lote actual\n",
    "            query = f\"SELECT numero_del_contrato, numero_de_proceso, nit_de_la_entidad, documento_proveedor, estado_del_proceso LIMIT {limit} OFFSET {offset}\"\n",
    "            results = client.get(codigo_dataset, query=query) \n",
    "\n",
    "            # Si la API no devuelve más registros, se termina el bucle\n",
    "            if not results:\n",
    "                print(\"Carga de datos finalizada.\")\n",
    "                break\n",
    "\n",
    "            # Convierte el lote a un DataFrame de Spark y lo escribe en la tabla Delta\n",
    "            spark.createDataFrame(results).write \\\n",
    "                .format(\"delta\") \\\n",
    "                .mode(write_mode) \\\n",
    "                .option(\"overwriteSchema\", \"true\") \\\n",
    "                .saveAsTable(\"main.diplomado_datos.ids_contratos_procesos\")\n",
    "\n",
    "            print(f\"Lote de {len(results)} registros desde offset {offset} cargado.\")\n",
    "\n",
    "            # Se cambia a modo 'append' para las siguientes iteraciones y se incrementa el offset\n",
    "            write_mode = \"append\"\n",
    "            offset += limit\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            intentos +=1\n",
    "            print(\"Error al obtener o cargar el lote:\", e)\n",
    "            print(f\"Intento {intentos} de {reintentos}...\")\n",
    "            time.sleep(20)\n",
    "    else:\n",
    "        print(\"Se alcanzó el número máximo de intentos. Terminando la carga.\")\n",
    "        break\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7991ce55-e6cb-4134-a807-a5e0b66a3dfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_secop_id=spark.table(\"main.diplomado_datos.ids_contratos_procesos\")\n",
    "df_secop_id.count()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de8b0311-644d-42ff-943a-0eb166479040",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importar las funciones necesarias de PySpark\n",
    "from pyspark.sql.functions import sha2, concat_ws, col\n",
    "\n",
    "# 1. Cargar la tabla correcta desde el catálogo a un DataFrame\n",
    "# Se asume que esta es la tabla que contiene las columnas que mencionaste.\n",
    "df_secop_id = spark.table(\"main.diplomado_datos.ids_contratos_procesos\")\n",
    "\n",
    "# 2. Definir la lista corregida de columnas para el identificador único\n",
    "columnas_para_hash = [\n",
    "    \"numero_del_contrato\",\n",
    "    \"numero_de_proceso\",\n",
    "    \"nit_de_la_entidad\",\n",
    "    \"documento_proveedor\",\n",
    "    \"estado_del_proceso\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04c333f0-e680-4397-9d5a-d710f1a85b3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Añadir la nueva columna 'id_unico'\n",
    "# Se concatenan las columnas clave con un separador y se les aplica un hash SHA-2.\n",
    "df_con_id = df_secop_id.withColumn(\n",
    "    \"id_unico_con_estado\",\n",
    "    sha2(concat_ws(\"||\", *[col(c) for c in columnas_para_hash]), 256)\n",
    ")\n",
    "\n",
    "columnas_para_hash_se = [\n",
    "    \"numero_del_contrato\",\n",
    "    \"numero_de_proceso\",\n",
    "    \"nit_de_la_entidad\",\n",
    "    \"documento_proveedor\"\n",
    "]\n",
    "df_con_id = df_con_id.withColumn(\n",
    "    \"id_unico_sin_estado\",\n",
    "    sha2(concat_ws(\"||\", *[col(c) for c in columnas_para_hash_se]), 256)\n",
    ")\n",
    "df_con_id.display()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67728bf7-034d-44b6-8cf2-24c02569752c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_con_id.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"main.diplomado_datos.secop_id_bronze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25561ee7-801f-4b47-862f-3d5f33bfa396",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Explorar dataset\n",
    "SELECT * FROM main.diplomado_datos.secop_id_bronze LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2208d02-86db-4883-8c0e-c1f94aa92496",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "columnas_clave = [\n",
    "    \"numero_del_contrato\", \"numero_de_proceso\", \"nit_de_la_entidad\", \n",
    "    \"documento_proveedor\", \"estado_del_proceso\"\n",
    "]\n",
    "\n",
    "# Columnas faltantes\n",
    "columnas_faltantes = [\n",
    "    \"nivel_entidad\", \"codigo_entidad_en_secop\", \"nombre_de_la_entidad\", \n",
    "    \"departamento_entidad\", \"municipio_entidad\", \"modalidad_de_contrataci_n\", \n",
    "    \"objeto_a_contratar\", \"objeto_del_proceso\", \"tipo_de_contrato\", \n",
    "    \"fecha_de_firma_del_contrato\", \"fecha_inicio_ejecuci_n\", \"fecha_fin_ejecuci_n\", \n",
    "    \"valor_contrato\", \"nom_raz_social_contratista\", \"url_contrato\", \"origen\", \n",
    "    \"tipo_documento_proveedor\"\n",
    "]\n",
    "\n",
    "# Unir todas las columnas\n",
    "columnas_total = columnas_clave + columnas_faltantes\n",
    "query_cols = \", \".join(columnas_total)\n",
    "\n",
    "# Parámetros de paginación\n",
    "limit = 500000  \n",
    "offset = 0\n",
    "write_mode = \"overwrite\"\n",
    "reintentos = 5\n",
    "max_time = datetime.datetime.now() + datetime.timedelta(hours=2)  # Limitar el tiempo de ejecución a 2 horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25ac4df6-f929-4934-b4e8-a4b4f46f2213",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    if datetime.datetime.now() > max_time:\n",
    "        print(\"⏱️ Se alcanzó el tiempo máximo de ejecución. Terminando el proceso.\")\n",
    "        break\n",
    "    \n",
    "    intentos = 0\n",
    "    while intentos < reintentos:\n",
    "        try:\n",
    "            print(f\"Obteniendo y cargando lote con offset {offset}...\")\n",
    "\n",
    "            # Construir la consulta para el lote actual\n",
    "            query = f\"SELECT {query_cols} LIMIT {limit} OFFSET {offset}\"\n",
    "            results = client.get(codigo_dataset, query=query)\n",
    "\n",
    "            if not results:\n",
    "                print(\"✅ No hay más registros que descargar.\")\n",
    "                break\n",
    "\n",
    "            # Crear un DataFrame de Spark con los resultados\n",
    "            df_restante = spark.createDataFrame(results)\n",
    "\n",
    "            # Guardar los datos en la tabla temporal\n",
    "            df_restante.write \\\n",
    "                .format(\"delta\") \\\n",
    "                .mode(write_mode) \\\n",
    "                .option(\"overwriteSchema\", \"true\") \\\n",
    "                .saveAsTable(\"main.diplomado_datos.secop_restante_tmp\")\n",
    "\n",
    "            print(f\"✓ Lote de {len(results)} registros cargado.\")\n",
    "\n",
    "            # A partir del segundo lote, usar append\n",
    "            write_mode = \"append\"\n",
    "            offset += limit\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            intentos += 1\n",
    "            print(f\"Error en intento {intentos}: {e}\")\n",
    "            time.sleep(10)\n",
    "    else:\n",
    "        print(\"⚠️ Se alcanzó el número máximo de intentos.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c3918c7-6556-4e68-bb2c-064e3191e29d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Parámetros de paginación\n",
    "limit = 500000  # O ajustar según capacidad\n",
    "offset = 13000000  # Continuar desde el offset 13 millones\n",
    "write_mode = \"overwrite\"\n",
    "reintentos = 5\n",
    "max_time = datetime.datetime.now() + datetime.timedelta(hours=2)  # Limitar el tiempo de ejecución a 2 horas\n",
    "\n",
    "# Bucle para obtener y cargar datos por lotes\n",
    "while True:\n",
    "    if datetime.datetime.now() > max_time:\n",
    "        print(\"⏱️ Se alcanzó el tiempo máximo de ejecución. Terminando el proceso.\")\n",
    "        break\n",
    "    \n",
    "    intentos = 0\n",
    "    while intentos < reintentos:\n",
    "        try:\n",
    "            print(f\"Obteniendo y cargando lote con offset {offset}...\")\n",
    "\n",
    "            # Construir la consulta para el lote actual\n",
    "            query = f\"SELECT {query_cols} LIMIT {limit} OFFSET {offset}\"\n",
    "            results = client.get(codigo_dataset, query=query)\n",
    "\n",
    "            if not results:\n",
    "                print(\"✅ No hay más registros que descargar.\")\n",
    "                break\n",
    "\n",
    "            # Crear un DataFrame de Spark con los resultados\n",
    "            df_restante = spark.createDataFrame(results)\n",
    "\n",
    "            # Guardar los datos en la tabla temporal\n",
    "            df_restante.write \\\n",
    "                .format(\"delta\") \\\n",
    "                .mode(write_mode) \\\n",
    "                .option(\"overwriteSchema\", \"true\") \\\n",
    "                .saveAsTable(\"main.diplomado_datos.secop_restante_tmp\")\n",
    "\n",
    "            print(f\"✓ Lote de {len(results)} registros cargado.\")\n",
    "\n",
    "            # A partir del segundo lote, usar append\n",
    "            write_mode = \"append\"\n",
    "            offset += limit  # Incrementar el offset en cada iteración\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            intentos += 1\n",
    "            print(f\"Error en intento {intentos}: {e}\")\n",
    "            time.sleep(10)\n",
    "    else:\n",
    "        print(\"⚠️ Se alcanzó el número máximo de intentos.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc974c0c-869e-454d-8b13-a6ee634000e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cargar la tabla de la que se van a juntar los datos\n",
    "df_ids = spark.table(\"main.diplomado_datos.secop_id_bronze\")\n",
    "\n",
    "# Calcular el id único\n",
    "df_restante = df_restante.withColumn(\n",
    "    \"id_unico_con_estado\",\n",
    "    sha2(\n",
    "        concat_ws(\"||\",\n",
    "                  col(\"numero_del_contrato\"),\n",
    "                  col(\"numero_de_proceso\"),\n",
    "                  col(\"nit_de_la_entidad\"),\n",
    "                  col(\"documento_proveedor\"),\n",
    "                  col(\"estado_del_proceso\")\n",
    "        ), 256\n",
    "    )\n",
    ")\n",
    "\n",
    "# Seleccionar las columnas de interés\n",
    "columnas_restante = [\n",
    "    c for c in df_restante.columns\n",
    "    if c not in df_ids.columns or c == \"id_unico_con_estado\"\n",
    "]\n",
    "\n",
    "df_restante_reduced = df_restante.select(columnas_restante)\n",
    "print(f\"Columnas seleccionadas: {df_restante_reduced.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52472950-42ea-4a8a-8884-02c6e35aed2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Realizar el join usando el id único\n",
    "df_final = df_ids.join(\n",
    "    df_restante_reduced.dropDuplicates([\"id_unico_con_estado\"]),\n",
    "    on=\"id_unico_con_estado\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Guardar el resultado final en la tabla\n",
    "df_final.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"main.diplomado_datos.secop_completo\")\n",
    "\n",
    "print(\"✅ Ingesta y procesamiento completado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a142935-d220-42a3-a485-f0a4caa46ece",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "986508b2-5e06-41d0-a2c1-19b62969b4ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%sql\n",
    "SELECT COUNT(*) AS total_filas\n",
    "FROM main.diplomado_datos.secop_completo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c219f05c-d8f7-48bf-b69c-93307588eddd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%sql\n",
    "SELECT *\n",
    "FROM main.diplomado_datos.secop_completo\n",
    "LIMIT 15;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "sodapy == 2.2.0"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8967829804364313,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingesta Final",
   "widgets": {
    "codigo_dataset": {
     "currentValue": "rpmr-utcd",
     "nuid": "d4c166d7-48a2-4975-8353-e613839b6adc",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "rpmr-utcd",
      "label": "",
      "name": "codigo_dataset",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "rpmr-utcd",
      "label": "",
      "name": "codigo_dataset",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
