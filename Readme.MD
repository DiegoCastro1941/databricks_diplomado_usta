# **Procesamiento de Datos desde APIs usando Apache Spark en Databricks**

Este proyecto est√° dise√±ado para **procesar datos desde APIs p√∫blicas** utilizando **Apache Spark** en el entorno de **Databricks**, permitiendo la carga, transformaci√≥n y visualizaci√≥n de datos provenientes de APIs abiertas de Colombia.

---

## ‚úÖ **Objetivo del Proyecto**

El objetivo de este programa es:

1. **Conectarse a dos APIs p√∫blicas** de datos abiertos en Colombia (SECOP y MEN).
2. **Descargar archivos CSV** directamente desde las URLs proporcionadas por las APIs.
3. **Cargar los datos en DataFrames** de Apache Spark para su posterior an√°lisis y manipulaci√≥n.
4. **Realizar transformaciones y limpieza de los datos** para asegurar su calidad y precisi√≥n.
5. **Visualizar los datos** usando herramientas integradas de Databricks.
6. **Preparar los datos para an√°lisis futuros**, permitiendo su almacenamiento y exportaci√≥n a otros formatos como Parquet o CSV.

---

## üîó **APIs Utilizadas**

### **1. SECOP (Sistema Electr√≥nico para la Contrataci√≥n P√∫blica)**

- **Descripci√≥n**: El SECOP es una plataforma del gobierno colombiano que centraliza los procesos de contrataci√≥n p√∫blica, garantizando la transparencia y eficiencia de los contratos.
- **URL CSV**: [https://www.datos.gov.co/resource/rpmr-utcd.csv](https://www.datos.gov.co/resource/rpmr-utcd.csv)
- **Datos disponibles**: Informaci√≥n sobre contratos, proveedores, y entidades p√∫blicas.

### **2. MEN (Ministerio de Educaci√≥n Nacional)**

- **Descripci√≥n**: API del Ministerio de Educaci√≥n Nacional de Colombia con datos sobre la cobertura educativa, tasas de matr√≠cula y estad√≠sticas relacionadas al sistema educativo.
- **URL CSV**: [https://www.datos.gov.co/resource/nudc-7mev.csv](https://www.datos.gov.co/resource/nudc-7mev.csv)
- **Datos disponibles**: Informaci√≥n sobre poblaci√≥n estudiantil, cobertura y tasas de matr√≠cula por departamento y municipio.

---

## ‚úÖ **Consideraciones Importantes**

- **Tama√±o de los Archivos**: Los archivos CSV pueden ser grandes, por lo que se recomienda verificar la capacidad del cluster en Databricks antes de cargarlos.
- **Accesibilidad de las APIs**: Las URLs de las APIs deben estar accesibles p√∫blicamente. Si se requiere autenticaci√≥n o tokens API, ser√° necesario adaptarlo.
- **Adaptabilidad**: El proceso est√° configurado para trabajar con archivos CSV, pero puede adaptarse a otros formatos como JSON o Parquet, seg√∫n el caso de uso.
- **Validaci√≥n de Datos**: Es importante validar los esquemas de los datos para asegurarse de que las lecturas y transformaciones se realicen correctamente.
- **Calidad de los Datos**: Asegurarse de que los datos no contengan valores nulos o inconsistencias que puedan afectar los an√°lisis posteriores.

---

## üõ† **Pasos del Proyecto**

### 1. **Configuraci√≥n del Cluster en Databricks**
   - Aseg√∫rate de tener un cluster adecuado en Databricks con suficiente memoria y recursos para procesar grandes vol√∫menes de datos. Si los archivos CSV son grandes, considera aumentar la memoria del cluster.

### 2. **Descarga de los Archivos desde las APIs**
   - Utiliza Python o herramientas integradas en Databricks para realizar solicitudes HTTP a las APIs y descargar los archivos CSV. A continuaci√≥n, se muestra un ejemplo b√°sico para la descarga de archivos:
   
   ```python
   import requests

   url_secop = "https://www.datos.gov.co/resource/rpmr-utcd.csv"
   url_men = "https://www.datos.gov.co/resource/nudc-7mev.csv"

   # Descargar el archivo de SECOP
   response_secop = requests.get(url_secop)
   if response_secop.status_code == 200:
       with open("/dbfs/tmp/SECOP.csv", "wb") as f:
           f.write(response_secop.content)

   # Descargar el archivo del MEN
   response_men = requests.get(url_men)
   if response_men.status_code == 200:
       with open("/dbfs/tmp/MEN.csv", "wb") as f:
           f.write(response_men.content)
